{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.llms.openai import OpenAI\n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "# from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "# from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# llm = OpenAI(model_name=\"gpt-3.5-turbo-1106\")\n",
    "# * the higher the more creative\n",
    "# chat = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "# a = llm.predict(\"How many planets are there?\")\n",
    "# b = chat.predict(\"How many planets are there?\")\n",
    "\n",
    "# a, b\n",
    "\n",
    "# template = PromptTemplate.from_template(\"What is the distance between {country_a} and {country_b}\",)\n",
    "\n",
    "# prompt = template.format(country_a=\"Maxico\", country_b=\"Thailand\")\n",
    "\n",
    "# chat.predict(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.schema import BaseOutputParser\n",
    "\n",
    "\n",
    "# class CommaOutputParser(BaseOutputParser):\n",
    "\n",
    "# def parse(self, text):\n",
    "#     items = text.strip().split(\",\")\n",
    "#     return list(map(str.strip, items))\n",
    "\n",
    "\n",
    "# p = CommaOutputParser()\n",
    "\n",
    "# p.parse(\" Hello,how,are,you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.schema import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "\n",
    "# template = ChatPromptTemplate.from_messages(\n",
    "#     [\n",
    "#         (\n",
    "#             \"system\",\n",
    "#             \"You are a geography expert. And you only reply in {language}.\",\n",
    "#         ),\n",
    "#         (\n",
    "#             \"ai\",\n",
    "#             \"Ciao, mi chiamo {name}!\",\n",
    "#         ),\n",
    "#         (\n",
    "#             \"human\",\n",
    "#             \"What is the distance between {country_a} and {country_b} and also, what is your name?\",\n",
    "#         ),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# prompt = template.format_messages(\n",
    "#     language=\"Greek\",\n",
    "#     name=\"Socrates\",\n",
    "#     country_a=\"Maxico\",\n",
    "#     country_b=\"Thailand\",\n",
    "# )\n",
    "\n",
    "# chat.predict_messages(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# template = ChatPromptTemplate.from_messages(\n",
    "#     [\n",
    "#         (\n",
    "#             \"system\",\n",
    "#             \"You are a list generating machine. Everything you are asked will be answered with a comma seperated list of max {max_items} in lower case. Do NOT reply with anything else.\",\n",
    "#         ),\n",
    "#         (\"human\", \"{country}\",),\n",
    "#     ])\n",
    "\n",
    "# prompt = template.format_messages(\n",
    "#     max_items=10,\n",
    "#     question=\"What are the colors?\"\n",
    "# )\n",
    "\n",
    "# result = chat.predict_messages(prompt)\n",
    "\n",
    "# p = CommaOutputParser()\n",
    "\n",
    "# p.parse(result.content) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain = template | chat | CommaOutputParser()\n",
    "\n",
    "# chain.invoke({\n",
    "#     \"max_items\":5,\n",
    "#     \"question\":\"What are the pokemons?\"\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.chat_models import ChatOpenAI\n",
    "# from langchain.prompts import ChatPromptTemplate\n",
    "# from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "\n",
    "# chat = ChatOpenAI(\n",
    "#     temperature=0.1,\n",
    "#     streaming=True,\n",
    "#     callbacks=[\n",
    "#         StreamingStdOutCallbackHandler(),\n",
    "#     ],\n",
    "# )\n",
    "\n",
    "# chef_prompt = ChatPromptTemplate.from_messages(\n",
    "#     [\n",
    "#         (\n",
    "#             \"system\",\n",
    "#             \"You are a world-class international chef. You create easy to follow recipies for any type of cuisine with easy to find ingredients\",\n",
    "#         ),\n",
    "#         (\n",
    "#             \"human\",\n",
    "#             \"I want to cook {cuisine} food.\",\n",
    "#         ),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# chef_chain = chef_prompt | chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# veg_chef_prompt = ChatPromptTemplate.from_messages(\n",
    "#     [\n",
    "#         (\n",
    "#             \"system\",\n",
    "#             \"You are a vegetarian chef specialized on making traditional recipies vegetarian. You find alternative ingredients and explain their preparation. You don't radically modify the recipe. If there is no alternatie for a food just say you don't know how to replace it.\",\n",
    "#         ),\n",
    "#         (\n",
    "#             \"human\",\n",
    "#             \"{recipe}\",\n",
    "#         ),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# veg_chain = veg_chef_prompt | chat\n",
    "\n",
    "\n",
    "# final_chain = {\"recipe\": chef_chain} | veg_chain\n",
    "\n",
    "# final_chain.invoke(\n",
    "#     {\n",
    "#         \"cuisine\": \"indian\",\n",
    "#     }\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from typing import Any, Dict, List\n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "# from langchain.prompts import example_selector\n",
    "# from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "# from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "# from langchain.prompts import PromptTemplate\n",
    "# from langchain.prompts.example_selector.base import BaseExampleSelector\n",
    "\n",
    "\n",
    "# chat = ChatOpenAI(\n",
    "#     temperature=0.1,\n",
    "#     streaming=True,\n",
    "#     callbacks=[\n",
    "#         StreamingStdOutCallbackHandler(),\n",
    "#     ],\n",
    "# )\n",
    "\n",
    "# examples = [\n",
    "#     {\n",
    "#         \"country\": \"France\",\n",
    "#         \"answer\": \"\"\"\n",
    "#         Here is what I know:\n",
    "#         Capital: Paris\n",
    "#         Language: French\n",
    "#         Food: Wine and Cheese\n",
    "#         Currency: Euro\n",
    "#         \"\"\",\n",
    "#     },\n",
    "#     {\n",
    "#         \"country\": \"Italy\",\n",
    "#         \"answer\": \"\"\"\n",
    "#         I know this:\n",
    "#         Capital: Rome\n",
    "#         Language: Italian\n",
    "#         Food: Pizza and Pasta\n",
    "#         Currency: Euro\n",
    "#         \"\"\",\n",
    "#     },\n",
    "#     {\n",
    "#         \"country\": \"Greece\",\n",
    "#         \"answer\": \"\"\"\n",
    "#         I know this:\n",
    "#         Capital: Athens\n",
    "#         Language: Greek\n",
    "#         Food: Souvlaki and Feta Cheese\n",
    "#         Currency: Euro\n",
    "#         \"\"\",\n",
    "#     },\n",
    "# ]\n",
    "\n",
    "\n",
    "# class RandomExampleSelector(BaseExampleSelector):\n",
    "\n",
    "#     def __init__(self, examples):\n",
    "#         self.examples = examples\n",
    "\n",
    "#     def add_example(self, example):\n",
    "#         self.examples.append(examples)\n",
    "\n",
    "#     def select_examples(self, input_variables):\n",
    "#         from random import choice\n",
    "\n",
    "#         return [choice(self.examples)]\n",
    "\n",
    "\n",
    "# example_prompt = PromptTemplate.from_template(\"Human: {country}\\nAI:{answer}\")\n",
    "\n",
    "\n",
    "# example_selector = RandomExampleSelector(\n",
    "#     examples=examples,\n",
    "# )\n",
    "\n",
    "# prompt = FewShotPromptTemplate(\n",
    "#     example_prompt=example_prompt,\n",
    "#     example_selector=example_selector,\n",
    "#     suffix=\"Human: What do you know about {country}?\",\n",
    "#     input_variables=[\"country\"],\n",
    "# )\n",
    "\n",
    "# prompt.format(country=\"Brazil\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arrr! Me favorite food be a good ol' plate o' fish 'n chips, matey! Aye, nothin' like some fresh seafood to satisfy me pirate belly. Arrr!"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content=\"Arrr! Me favorite food be a good ol' plate o' fish 'n chips, matey! Aye, nothin' like some fresh seafood to satisfy me pirate belly. Arrr!\")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from langchain.chat_models import ChatOpenAI\n",
    "# from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "# from langchain.prompts import PromptTemplate\n",
    "# from langchain.prompts.pipeline import PipelinePromptTemplate\n",
    "\n",
    "\n",
    "# chat = ChatOpenAI(\n",
    "#     temperature=0.1,\n",
    "#     streaming=True,\n",
    "#     callbacks=[\n",
    "#         StreamingStdOutCallbackHandler(),\n",
    "#     ],\n",
    "# )\n",
    "\n",
    "# intro = PromptTemplate.from_template(\n",
    "#     \"\"\"\n",
    "#     You are a role playing assistant.\n",
    "#     And you are impersonating a {character}\n",
    "#     \"\"\"\n",
    "# )\n",
    "\n",
    "# example = PromptTemplate.from_template(\n",
    "#     \"\"\"\n",
    "#     This is an example of how you talk:\n",
    "\n",
    "#     Human: {example_question}\n",
    "#     You: {example_answer}\n",
    "#     \"\"\"\n",
    "# )\n",
    "\n",
    "# start = PromptTemplate.from_template(\n",
    "#     \"\"\"\n",
    "#     Start now!\n",
    "\n",
    "#     Human: {question}\n",
    "#     You:\n",
    "#     \"\"\"\n",
    "# )\n",
    "\n",
    "# final = PromptTemplate.from_template(\n",
    "#     \"\"\"\n",
    "#     {intro}\n",
    "\n",
    "#     {example}\n",
    "\n",
    "#     {start}\n",
    "#     \"\"\"\n",
    "# )\n",
    "\n",
    "# prompts = [\n",
    "#     (\"intro\", intro),\n",
    "#     (\"example\", example),\n",
    "#     (\"start\", start),\n",
    "# ]\n",
    "# full_prompt = PipelinePromptTemplate(\n",
    "#     final_prompt=final,\n",
    "#     pipeline_prompts=prompts,\n",
    "# )\n",
    "\n",
    "# chain = full_prompt | chat\n",
    "\n",
    "# chain.invoke(\n",
    "#     {\n",
    "#         \"character\": \"Pirate\",\n",
    "#         \"example_question\": \"What is your location?\",\n",
    "#         \"example_answer\": \"Arrrg!\",\n",
    "#         \"question\": \"What is your favourite food?\",\n",
    "#     }\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.chat_models import ChatOpenAI\n",
    "# from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "# from langchain.globals import set_llm_cache, set_debug\n",
    "# from langchain.cache import InMemoryCache, SQLiteCache\n",
    "\n",
    "# set_llm_cache(SQLiteCache(\"cache.db\"))\n",
    "\n",
    "# chat = ChatOpenAI(\n",
    "#     temperature=0.1,\n",
    "#     # streaming=True,\n",
    "#     # callbacks=[\n",
    "#     #     StreamingStdOutCallbackHandler(),\n",
    "#     # ],\n",
    "# )\n",
    "\n",
    "# chat.predict(\"How do you make an Italian pasta?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat.predict(\"How do you make an Italian pasta?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.chat_models import ChatOpenAI\n",
    "# from langchain.llms.openai import OpenAI\n",
    "# from langchain.llms.loading import load_llm\n",
    "\n",
    "# chat = load_llm(\"model.json\")\n",
    "\n",
    "# chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# memory = ConversationBufferMemory(return_messages=True)\n",
    "\n",
    "# memory.save_context({\"input\": \"Hi!\"}, {\"output\":\"How are you?\"})\n",
    "\n",
    "# memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "# memory = ConversationBufferWindowMemory(return_messages=True, k=4)\n",
    "\n",
    "\n",
    "# def add_messages(input, output):\n",
    "#     memory.save_context({\"input\": input}, {\"output\": output})\n",
    "\n",
    "\n",
    "# add_messages(1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_messages(2, 2)\n",
    "# add_messages(3, 3)\n",
    "# add_messages(4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_messages(5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.memory import ConversationSummaryMemory\n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "# memory = ConversationSummaryMemory(llm=llm)\n",
    "\n",
    "# def add_messages(input, output):\n",
    "#     memory.save_context({\"input\": input}, {\"output\": output})\n",
    "\n",
    "# def get_history():\n",
    "#     return memory.load_memory_variables({})\n",
    "\n",
    "# add_messages(\"Hi I'm Sue, I lived in Australia\", \"Wow, that's amazing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_messages(\"Australia is so pretty\", \"I want to go there\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.memory import ConversationSummaryBufferMemory\n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "# memory = ConversationSummaryBufferMemory(\n",
    "#     llm=llm,\n",
    "#     max_token_limit=150,\n",
    "#     return_messages=True,\n",
    "# )\n",
    "\n",
    "\n",
    "# def add_messages(input, output):\n",
    "#     memory.save_context({\"input\": input}, {\"output\": output})\n",
    "\n",
    "\n",
    "# def get_history():\n",
    "#     return memory.load_memory_variables({})\n",
    "\n",
    "\n",
    "# add_messages(\"Hi I'm Sue, I lived in Australia\", \"Wow, that's amazing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_messages(\"Australia is so pretty\", \"I want to go there\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_messages(\"Australia has koalas, kangaroos, and quokkas\", \"they are so adorable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_messages(\"Australia is a good place for surfing, enjoying nature. What part of Australia do you want to visit?\", \"I would like to visit every single part of Australia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.memory import ConversationKGMemory\n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "# memory = ConversationKGMemory(\n",
    "#     llm=llm,\n",
    "#     return_messages=True,\n",
    "# )\n",
    "\n",
    "\n",
    "# def add_messages(input, output):\n",
    "#     memory.save_context({\"input\": input}, {\"output\": output})\n",
    "\n",
    "\n",
    "# add_messages(\n",
    "#     \"Halo halo, nice to meet you. I'm Sue from South Korea\", \"Nice to meet you, too!\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memory.load_memory_variables({\"input\":\"Who is Sue?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_messages(\"Sue likes quokkas\", \"I like too\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memory.load_memory_variables({\"input\":\"What does Sue like?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invoke_chain(\"My name is Sue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invoke_chain(\"What is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Miss Austen, also known as Jane Austen, was a renowned English novelist known for her exceptional storytelling and unique style of writing. She has been compared to literary giants such as Swift, Fielding, and Thackeray for her ability to create characters that give readers \"pleasant shocks\" and \"delightful thrills.\" Austen\\'s talent in portraying the goodness and flaws of minor characters, such as Mrs. Bennet, Kitty, Lydia, and Mary, with unerring skill sets her apart from other authors. Despite her unkind treatment of some characters, like Mary, Austen\\'s portrayal reflects the societal norms and expectations of her time. The intricate details and nuances Austen weaves into her characters and storylines continue to captivate readers, making her novels enduring classics in English literature.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings, CacheBackedEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "cache_dir = LocalFileStore(\"./.cache/\")\n",
    "\n",
    "splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=600,\n",
    "    chunk_overlap=100,\n",
    ")\n",
    "\n",
    "loader = UnstructuredFileLoader(\"./files/preface.docx\")\n",
    "\n",
    "docs = loader.load_and_split(text_splitter=splitter)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "cached_embeddings = CacheBackedEmbeddings.from_bytes_store(\n",
    "    embeddings,\n",
    "    cache_dir,\n",
    ")\n",
    "\n",
    "vectorstore = FAISS.from_documents(\n",
    "    docs,\n",
    "    cached_embeddings,\n",
    ")\n",
    "\n",
    "chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"map_rerank\",\n",
    "    retriever=vectorstore.as_retriever(),\n",
    ")\n",
    "\n",
    "chain.run(\"Who is miss Austen?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='The characteristics of Miss Austen’s humour are so subtle and delicate that they are, perhaps, at all times easier to apprehend than to express, and at any particular\\n{xiii}\\n time likely to be differently apprehended by different persons. To me this humour seems to possess a greater affinity, on the whole, to that of Addison than to any other of the numerous species of this great British genus. The differences of scheme, of time, of subject, of literary convention, are, of course, obvious enough; the difference of sex does not, perhaps, count for much, for there was a distinctly feminine element in “Mr. Spectator,” and in Jane Austen’s genius there was, though nothing mannish, much that was masculine. But the likeness of quality consists in a great number of common subdivisions of quality—demureness, extreme minuteness of touch, avoidance of loud tones and glaring effects. Also there is in both a certain not inhuman or unamiable cruelty. It is the custom with those who judge grossly to contrast the good nature of Addison with the savagery of Swift, the mildness of Miss Austen with the boisterousness of Fielding and Smollett, even with the ferocious practical jokes that her immediate predecessor, Miss Burney, allowed without very much protest. Yet, both in Mr. Addison and in Miss Austen there is, though a restrained and well-mannered, an insatiable and ruthless delight in roasting and cutting up a fool. A man in the early eighteenth century, of course, could push this taste further than a lady in the early nineteenth; and no doubt Miss Austen’s principles, as well as her heart, would have shrunk from such things as the letter from the unfortunate husband in the Spectator, who describes, with all the gusto and all the innocence in the world, how his wife and his friend induce him to play at blind-man’s-buff. But another Spectator letter—that of the damsel of fourteen who\\n{xiv}', metadata={'source': './files/preface.docx'}),\n",
       " Document(page_content='The secret of that charm many men and not a few women, from Miss Austen herself downwards, have felt, and like most charms it is a thing rather to be felt than to be explained. Elizabeth of course belongs to the allegro or allegra division of the army of Venus. Miss Austen was always provokingly chary of description in regard to her beauties; and except the fine eyes, and a hint or two that she had at any rate sometimes a bright complexion, and was not very tall, we hear nothing about her looks. But her chief difference from other heroines of the lively type seems to lie first in her being distinctly clever—almost strong-minded, in the better sense of that objectionable word—and secondly in her being entirely destitute of ill-nature for all her propensity to tease and the sharpness of her tongue. Elizabeth can give at least as good as she gets when she is attacked; but she never “scratches,” and she never attacks first. Some of the merest obsoletenesses of phrase and\\n{xxii}\\n manner give one or two of her early speeches a slight pertness, but that is nothing, and when she comes to serious business, as in the great proposal scene with Darcy (which is, as it should be, the climax of the interest of the book), and in the final ladies’ battle with Lady Catherine, she is unexceptionable. Then too she is a perfectly natural girl. She does not disguise from herself or anybody that she resents Darcy’s first ill-mannered personality with as personal a feeling. (By the way, the reproach that the ill-manners of this speech are overdone is certainly unjust; for things of the same kind, expressed no doubt less stiltedly but more coarsely, might have been heard in more than one ball-room during this very year from persons who ought to have been no worse bred than Darcy.) And she lets the injury done to Jane and the contempt shown to the rest of her family aggravate this resentment in the healthiest way in the world.', metadata={'source': './files/preface.docx'}),\n",
       " Document(page_content='{xix}\\n or are the result of previous study?” These are the things which give Miss Austen’s readers the pleasant shocks, the delightful thrills, which are felt by the readers of Swift, of Fielding, and we may here add, of Thackeray, as they are felt by the readers of no other English author of fiction outside of these four.\\nThe goodness of the minor characters in Pride and Prejudice has been already alluded to, and it makes a detailed dwelling on their beauties difficult in any space, and impossible in this. Mrs. Bennet we have glanced at, and it is not easy to say whether she is more exquisitely amusing or more horribly true. Much the same may be said of Kitty and Lydia; but it is not every author, even of genius, who would have differentiated with such unerring skill the effects of folly and vulgarity of intellect and disposition working upon the common weaknesses of woman at such different ages. With Mary, Miss Austen has taken rather less pains, though she has been even more unkind to her; not merely in the text, but, as we learn from those interesting traditional appendices which Mr. Austen Leigh has given us, in dooming her privately to marry “one of Mr. Philips’s clerks.” The habits of first copying and then retailing moral sentiments, of playing and singing too long in public, are, no doubt, grievous and criminal; but perhaps poor Mary was rather the scapegoat of the sins of blue stockings in that Fordyce-belectured generation. It is at any rate difficult not to extend to her a share of the respect and affection (affection and respect of a peculiar kind; doubtless), with which one regards Mr. Collins, when she draws the moral of Lydia’s fall. I\\n{xx}\\n sometimes wish that the exigencies of the story had permitted Miss Austen to unite these personages, and thus at once achieve a notable mating and soothe poor Mrs. Bennet’s anguish over the entail.', metadata={'source': './files/preface.docx'}),\n",
       " Document(page_content='In respect of her art generally, Mr. Goldwin Smith has truly observed that “metaphor has been exhausted in depicting the perfection of it, combined with the narrowness of her field;” and he has justly added that we need not go beyond her own comparison to the art of a miniature\\n{xv}\\n painter. To make this latter observation quite exact we must not use the term miniature in its restricted sense, and must think rather of Memling at one end of the history of painting and Meissonier at the other, than of Cosway or any of his kind. And I am not so certain that I should myself use the word “narrow” in connection with her. If her world is a microcosm, the cosmic quality of it is at least as eminent as the littleness. She does not touch what she did not feel herself called to paint; I am not so sure that she could not have painted what she did not feel herself called to touch. It is at least remarkable that in two very short periods of writing—one of about three years, and another of not much more than five—she executed six capital works, and has not left a single failure. It is possible that the romantic paste in her composition was defective: we must always remember that hardly anybody born in her decade—that of the eighteenth-century seventies—independently exhibited the full romantic quality. Even Scott required hill and mountain and ballad, even Coleridge metaphysics and German to enable them to chip the classical shell. Miss Austen was an English girl, brought up in a country retirement, at the time when ladies went back into the house if there was a white frost which might pierce their kid shoes, when a sudden cold was the subject of the gravest fears, when their studies, their ways, their conduct were subject to all those fantastic limits and restrictions against which Mary Wollstonecraft protested with better general sense than particular taste or judgment. Miss Austen, too, drew back when the white frost touched her shoes; but I think she would have made a pretty good journey even in a black one.\\n{xvi}', metadata={'source': './files/preface.docx'})]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vectorstore.similarity_search(\"Who is miss Austen\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
