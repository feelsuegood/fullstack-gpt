{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.llms.openai import OpenAI\n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "# from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "# from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# llm = OpenAI(model_name=\"gpt-3.5-turbo-1106\")\n",
    "# * the higher the more creative\n",
    "# chat = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "# a = llm.predict(\"How many planets are there?\")\n",
    "# b = chat.predict(\"How many planets are there?\")\n",
    "\n",
    "# a, b\n",
    "\n",
    "# template = PromptTemplate.from_template(\"What is the distance between {country_a} and {country_b}\",)\n",
    "\n",
    "# prompt = template.format(country_a=\"Maxico\", country_b=\"Thailand\")\n",
    "\n",
    "# chat.predict(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.schema import BaseOutputParser\n",
    "\n",
    "\n",
    "# class CommaOutputParser(BaseOutputParser):\n",
    "\n",
    "# def parse(self, text):\n",
    "#     items = text.strip().split(\",\")\n",
    "#     return list(map(str.strip, items))\n",
    "\n",
    "\n",
    "# p = CommaOutputParser()\n",
    "\n",
    "# p.parse(\" Hello,how,are,you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.schema import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "\n",
    "# template = ChatPromptTemplate.from_messages(\n",
    "#     [\n",
    "#         (\n",
    "#             \"system\",\n",
    "#             \"You are a geography expert. And you only reply in {language}.\",\n",
    "#         ),\n",
    "#         (\n",
    "#             \"ai\",\n",
    "#             \"Ciao, mi chiamo {name}!\",\n",
    "#         ),\n",
    "#         (\n",
    "#             \"human\",\n",
    "#             \"What is the distance between {country_a} and {country_b} and also, what is your name?\",\n",
    "#         ),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# prompt = template.format_messages(\n",
    "#     language=\"Greek\",\n",
    "#     name=\"Socrates\",\n",
    "#     country_a=\"Maxico\",\n",
    "#     country_b=\"Thailand\",\n",
    "# )\n",
    "\n",
    "# chat.predict_messages(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# template = ChatPromptTemplate.from_messages(\n",
    "#     [\n",
    "#         (\n",
    "#             \"system\",\n",
    "#             \"You are a list generating machine. Everything you are asked will be answered with a comma seperated list of max {max_items} in lower case. Do NOT reply with anything else.\",\n",
    "#         ),\n",
    "#         (\"human\", \"{country}\",),\n",
    "#     ])\n",
    "\n",
    "# prompt = template.format_messages(\n",
    "#     max_items=10,\n",
    "#     question=\"What are the colors?\"\n",
    "# )\n",
    "\n",
    "# result = chat.predict_messages(prompt)\n",
    "\n",
    "# p = CommaOutputParser()\n",
    "\n",
    "# p.parse(result.content) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain = template | chat | CommaOutputParser()\n",
    "\n",
    "# chain.invoke({\n",
    "#     \"max_items\":5,\n",
    "#     \"question\":\"What are the pokemons?\"\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.chat_models import ChatOpenAI\n",
    "# from langchain.prompts import ChatPromptTemplate\n",
    "# from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "\n",
    "# chat = ChatOpenAI(\n",
    "#     temperature=0.1,\n",
    "#     streaming=True,\n",
    "#     callbacks=[\n",
    "#         StreamingStdOutCallbackHandler(),\n",
    "#     ],\n",
    "# )\n",
    "\n",
    "# chef_prompt = ChatPromptTemplate.from_messages(\n",
    "#     [\n",
    "#         (\n",
    "#             \"system\",\n",
    "#             \"You are a world-class international chef. You create easy to follow recipies for any type of cuisine with easy to find ingredients\",\n",
    "#         ),\n",
    "#         (\n",
    "#             \"human\",\n",
    "#             \"I want to cook {cuisine} food.\",\n",
    "#         ),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# chef_chain = chef_prompt | chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# veg_chef_prompt = ChatPromptTemplate.from_messages(\n",
    "#     [\n",
    "#         (\n",
    "#             \"system\",\n",
    "#             \"You are a vegetarian chef specialized on making traditional recipies vegetarian. You find alternative ingredients and explain their preparation. You don't radically modify the recipe. If there is no alternatie for a food just say you don't know how to replace it.\",\n",
    "#         ),\n",
    "#         (\n",
    "#             \"human\",\n",
    "#             \"{recipe}\",\n",
    "#         ),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# veg_chain = veg_chef_prompt | chat\n",
    "\n",
    "\n",
    "# final_chain = {\"recipe\": chef_chain} | veg_chain\n",
    "\n",
    "# final_chain.invoke(\n",
    "#     {\n",
    "#         \"cuisine\": \"indian\",\n",
    "#     }\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from typing import Any, Dict, List\n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "# from langchain.prompts import example_selector\n",
    "# from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "# from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "# from langchain.prompts import PromptTemplate\n",
    "# from langchain.prompts.example_selector.base import BaseExampleSelector\n",
    "\n",
    "\n",
    "# chat = ChatOpenAI(\n",
    "#     temperature=0.1,\n",
    "#     streaming=True,\n",
    "#     callbacks=[\n",
    "#         StreamingStdOutCallbackHandler(),\n",
    "#     ],\n",
    "# )\n",
    "\n",
    "# examples = [\n",
    "#     {\n",
    "#         \"country\": \"France\",\n",
    "#         \"answer\": \"\"\"\n",
    "#         Here is what I know:\n",
    "#         Capital: Paris\n",
    "#         Language: French\n",
    "#         Food: Wine and Cheese\n",
    "#         Currency: Euro\n",
    "#         \"\"\",\n",
    "#     },\n",
    "#     {\n",
    "#         \"country\": \"Italy\",\n",
    "#         \"answer\": \"\"\"\n",
    "#         I know this:\n",
    "#         Capital: Rome\n",
    "#         Language: Italian\n",
    "#         Food: Pizza and Pasta\n",
    "#         Currency: Euro\n",
    "#         \"\"\",\n",
    "#     },\n",
    "#     {\n",
    "#         \"country\": \"Greece\",\n",
    "#         \"answer\": \"\"\"\n",
    "#         I know this:\n",
    "#         Capital: Athens\n",
    "#         Language: Greek\n",
    "#         Food: Souvlaki and Feta Cheese\n",
    "#         Currency: Euro\n",
    "#         \"\"\",\n",
    "#     },\n",
    "# ]\n",
    "\n",
    "\n",
    "# class RandomExampleSelector(BaseExampleSelector):\n",
    "\n",
    "#     def __init__(self, examples):\n",
    "#         self.examples = examples\n",
    "\n",
    "#     def add_example(self, example):\n",
    "#         self.examples.append(examples)\n",
    "\n",
    "#     def select_examples(self, input_variables):\n",
    "#         from random import choice\n",
    "\n",
    "#         return [choice(self.examples)]\n",
    "\n",
    "\n",
    "# example_prompt = PromptTemplate.from_template(\"Human: {country}\\nAI:{answer}\")\n",
    "\n",
    "\n",
    "# example_selector = RandomExampleSelector(\n",
    "#     examples=examples,\n",
    "# )\n",
    "\n",
    "# prompt = FewShotPromptTemplate(\n",
    "#     example_prompt=example_prompt,\n",
    "#     example_selector=example_selector,\n",
    "#     suffix=\"Human: What do you know about {country}?\",\n",
    "#     input_variables=[\"country\"],\n",
    "# )\n",
    "\n",
    "# prompt.format(country=\"Brazil\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.chat_models import ChatOpenAI\n",
    "# from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "# from langchain.prompts import PromptTemplate\n",
    "# from langchain.prompts.pipeline import PipelinePromptTemplate\n",
    "\n",
    "\n",
    "# chat = ChatOpenAI(\n",
    "#     temperature=0.1,\n",
    "#     streaming=True,\n",
    "#     callbacks=[\n",
    "#         StreamingStdOutCallbackHandler(),\n",
    "#     ],\n",
    "# )\n",
    "\n",
    "# intro = PromptTemplate.from_template(\n",
    "#     \"\"\"\n",
    "#     You are a role playing assistant.\n",
    "#     And you are impersonating a {character}\n",
    "#     \"\"\"\n",
    "# )\n",
    "\n",
    "# example = PromptTemplate.from_template(\n",
    "#     \"\"\"\n",
    "#     This is an example of how you talk:\n",
    "\n",
    "#     Human: {example_question}\n",
    "#     You: {example_answer}\n",
    "#     \"\"\"\n",
    "# )\n",
    "\n",
    "# start = PromptTemplate.from_template(\n",
    "#     \"\"\"\n",
    "#     Start now!\n",
    "\n",
    "#     Human: {question}\n",
    "#     You:\n",
    "#     \"\"\"\n",
    "# )\n",
    "\n",
    "# final = PromptTemplate.from_template(\n",
    "#     \"\"\"\n",
    "#     {intro}\n",
    "\n",
    "#     {example}\n",
    "\n",
    "#     {start}\n",
    "#     \"\"\"\n",
    "# )\n",
    "\n",
    "# prompts = [\n",
    "#     (\"intro\", intro),\n",
    "#     (\"example\", example),\n",
    "#     (\"start\", start),\n",
    "# ]\n",
    "# full_prompt = PipelinePromptTemplate(\n",
    "#     final_prompt=final,\n",
    "#     pipeline_prompts=prompts,\n",
    "# )\n",
    "\n",
    "# chain = full_prompt | chat\n",
    "\n",
    "# chain.invoke(\n",
    "#     {\n",
    "#         \"character\": \"Pirate\",\n",
    "#         \"example_question\": \"What is your location?\",\n",
    "#         \"example_answer\": \"Arrrg!\",\n",
    "#         \"question\": \"What is your favourite food?\",\n",
    "#     }\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.chat_models import ChatOpenAI\n",
    "# from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "# from langchain.globals import set_llm_cache, set_debug\n",
    "# from langchain.cache import InMemoryCache, SQLiteCache\n",
    "\n",
    "# set_llm_cache(SQLiteCache(\"cache.db\"))\n",
    "\n",
    "# chat = ChatOpenAI(\n",
    "#     temperature=0.1,\n",
    "#     # streaming=True,\n",
    "#     # callbacks=[\n",
    "#     #     StreamingStdOutCallbackHandler(),\n",
    "#     # ],\n",
    "# )\n",
    "\n",
    "# chat.predict(\"How do you make an Italian pasta?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat.predict(\"How do you make an Italian pasta?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.chat_models import ChatOpenAI\n",
    "# from langchain.llms.openai import OpenAI\n",
    "# from langchain.llms.loading import load_llm\n",
    "\n",
    "# chat = load_llm(\"model.json\")\n",
    "\n",
    "# chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# memory = ConversationBufferMemory(return_messages=True)\n",
    "\n",
    "# memory.save_context({\"input\": \"Hi!\"}, {\"output\":\"How are you?\"})\n",
    "\n",
    "# memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "# memory = ConversationBufferWindowMemory(return_messages=True, k=4)\n",
    "\n",
    "\n",
    "# def add_messages(input, output):\n",
    "#     memory.save_context({\"input\": input}, {\"output\": output})\n",
    "\n",
    "\n",
    "# add_messages(1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_messages(2, 2)\n",
    "# add_messages(3, 3)\n",
    "# add_messages(4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_messages(5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.memory import ConversationSummaryMemory\n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "# memory = ConversationSummaryMemory(llm=llm)\n",
    "\n",
    "# def add_messages(input, output):\n",
    "#     memory.save_context({\"input\": input}, {\"output\": output})\n",
    "\n",
    "# def get_history():\n",
    "#     return memory.load_memory_variables({})\n",
    "\n",
    "# add_messages(\"Hi I'm Sue, I lived in Australia\", \"Wow, that's amazing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_messages(\"Australia is so pretty\", \"I want to go there\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.memory import ConversationSummaryBufferMemory\n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "# memory = ConversationSummaryBufferMemory(\n",
    "#     llm=llm,\n",
    "#     max_token_limit=150,\n",
    "#     return_messages=True,\n",
    "# )\n",
    "\n",
    "\n",
    "# def add_messages(input, output):\n",
    "#     memory.save_context({\"input\": input}, {\"output\": output})\n",
    "\n",
    "\n",
    "# def get_history():\n",
    "#     return memory.load_memory_variables({})\n",
    "\n",
    "\n",
    "# add_messages(\"Hi I'm Sue, I lived in Australia\", \"Wow, that's amazing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_messages(\"Australia is so pretty\", \"I want to go there\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_messages(\"Australia has koalas, kangaroos, and quokkas\", \"they are so adorable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_messages(\"Australia is a good place for surfing, enjoying nature. What part of Australia do you want to visit?\", \"I would like to visit every single part of Australia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.memory import ConversationKGMemory\n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "# memory = ConversationKGMemory(\n",
    "#     llm=llm,\n",
    "#     return_messages=True,\n",
    "# )\n",
    "\n",
    "\n",
    "# def add_messages(input, output):\n",
    "#     memory.save_context({\"input\": input}, {\"output\": output})\n",
    "\n",
    "\n",
    "# add_messages(\n",
    "#     \"Halo halo, nice to meet you. I'm Sue from South Korea\", \"Nice to meet you, too!\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memory.load_memory_variables({\"input\":\"Who is Sue?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_messages(\"Sue likes quokkas\", \"I like too\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memory.load_memory_variables({\"input\":\"What does Sue like?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.memory import ConversationSummaryBufferMemory\n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "# from langchain.schema.runnable import RunnablePassthrough\n",
    "# from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "# llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "# memory = ConversationSummaryBufferMemory(\n",
    "#     llm=llm,\n",
    "#     max_token_limit=120,\n",
    "#     return_messages=True,\n",
    "# )\n",
    "\n",
    "# prompt = ChatPromptTemplate.from_messages(\n",
    "#     [\n",
    "#         (\"system\", \"You are a helpful AI talking to a human\"),\n",
    "#         MessagesPlaceholder(variable_name=\"history\"),\n",
    "#         (\"human\", \"{question}\"),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "\n",
    "# def load_memory(_):\n",
    "#     return memory.load_memory_variables({})[\"history\"]\n",
    "\n",
    "\n",
    "# chain = RunnablePassthrough.assign(history=load_memory) | prompt | llm\n",
    "\n",
    "\n",
    "# def invoke_chain(question):\n",
    "#     result = chain.invoke({\"question\": question})\n",
    "#     memory.save_context(\n",
    "#         {\"input\": question},\n",
    "#         {\"output\": str(result.content)},\n",
    "#     )\n",
    "#     print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invoke_chain(\"My name is Sue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invoke_chain(\"What is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings, CacheBackedEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.storage import LocalFileStore\n",
    "\n",
    "cache_dir = LocalFileStore(\"./.cache/\")\n",
    "\n",
    "splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=600,\n",
    "    chunk_overlap=100,\n",
    ")\n",
    "\n",
    "loader = UnstructuredFileLoader(\"./files/preface.docx\")\n",
    "\n",
    "docs = loader.load_and_split(text_splitter=splitter)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "cached_embeddings = CacheBackedEmbeddings.from_bytes_store(\n",
    "    embeddings,\n",
    "    cache_dir,\n",
    ")\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    docs,\n",
    "    cached_embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='The characteristics of Miss Austen’s humour are so subtle and delicate that they are, perhaps, at all times easier to apprehend than to express, and at any particular\\n{xiii}\\n time likely to be differently apprehended by different persons. To me this humour seems to possess a greater affinity, on the whole, to that of Addison than to any other of the numerous species of this great British genus. The differences of scheme, of time, of subject, of literary convention, are, of course, obvious enough; the difference of sex does not, perhaps, count for much, for there was a distinctly feminine element in “Mr. Spectator,” and in Jane Austen’s genius there was, though nothing mannish, much that was masculine. But the likeness of quality consists in a great number of common subdivisions of quality—demureness, extreme minuteness of touch, avoidance of loud tones and glaring effects. Also there is in both a certain not inhuman or unamiable cruelty. It is the custom with those who judge grossly to contrast the good nature of Addison with the savagery of Swift, the mildness of Miss Austen with the boisterousness of Fielding and Smollett, even with the ferocious practical jokes that her immediate predecessor, Miss Burney, allowed without very much protest. Yet, both in Mr. Addison and in Miss Austen there is, though a restrained and well-mannered, an insatiable and ruthless delight in roasting and cutting up a fool. A man in the early eighteenth century, of course, could push this taste further than a lady in the early nineteenth; and no doubt Miss Austen’s principles, as well as her heart, would have shrunk from such things as the letter from the unfortunate husband in the Spectator, who describes, with all the gusto and all the innocence in the world, how his wife and his friend induce him to play at blind-man’s-buff. But another Spectator letter—that of the damsel of fourteen who\\n{xiv}', metadata={'source': './files/preface.docx'}),\n",
       " Document(page_content='The characteristics of Miss Austen’s humour are so subtle and delicate that they are, perhaps, at all times easier to apprehend than to express, and at any particular\\n{xiii}\\n time likely to be differently apprehended by different persons. To me this humour seems to possess a greater affinity, on the whole, to that of Addison than to any other of the numerous species of this great British genus. The differences of scheme, of time, of subject, of literary convention, are, of course, obvious enough; the difference of sex does not, perhaps, count for much, for there was a distinctly feminine element in “Mr. Spectator,” and in Jane Austen’s genius there was, though nothing mannish, much that was masculine. But the likeness of quality consists in a great number of common subdivisions of quality—demureness, extreme minuteness of touch, avoidance of loud tones and glaring effects. Also there is in both a certain not inhuman or unamiable cruelty. It is the custom with those who judge grossly to contrast the good nature of Addison with the savagery of Swift, the mildness of Miss Austen with the boisterousness of Fielding and Smollett, even with the ferocious practical jokes that her immediate predecessor, Miss Burney, allowed without very much protest. Yet, both in Mr. Addison and in Miss Austen there is, though a restrained and well-mannered, an insatiable and ruthless delight in roasting and cutting up a fool. A man in the early eighteenth century, of course, could push this taste further than a lady in the early nineteenth; and no doubt Miss Austen’s principles, as well as her heart, would have shrunk from such things as the letter from the unfortunate husband in the Spectator, who describes, with all the gusto and all the innocence in the world, how his wife and his friend induce him to play at blind-man’s-buff. But another Spectator letter—that of the damsel of fourteen who\\n{xiv}', metadata={'source': './files/preface.docx'}),\n",
       " Document(page_content='The characteristics of Miss Austen’s humour are so subtle and delicate that they are, perhaps, at all times easier to apprehend than to express, and at any particular\\n{xiii}\\n time likely to be differently apprehended by different persons. To me this humour seems to possess a greater affinity, on the whole, to that of Addison than to any other of the numerous species of this great British genus. The differences of scheme, of time, of subject, of literary convention, are, of course, obvious enough; the difference of sex does not, perhaps, count for much, for there was a distinctly feminine element in “Mr. Spectator,” and in Jane Austen’s genius there was, though nothing mannish, much that was masculine. But the likeness of quality consists in a great number of common subdivisions of quality—demureness, extreme minuteness of touch, avoidance of loud tones and glaring effects. Also there is in both a certain not inhuman or unamiable cruelty. It is the custom with those who judge grossly to contrast the good nature of Addison with the savagery of Swift, the mildness of Miss Austen with the boisterousness of Fielding and Smollett, even with the ferocious practical jokes that her immediate predecessor, Miss Burney, allowed without very much protest. Yet, both in Mr. Addison and in Miss Austen there is, though a restrained and well-mannered, an insatiable and ruthless delight in roasting and cutting up a fool. A man in the early eighteenth century, of course, could push this taste further than a lady in the early nineteenth; and no doubt Miss Austen’s principles, as well as her heart, would have shrunk from such things as the letter from the unfortunate husband in the Spectator, who describes, with all the gusto and all the innocence in the world, how his wife and his friend induce him to play at blind-man’s-buff. But another Spectator letter—that of the damsel of fourteen who\\n{xiv}', metadata={'source': './files/preface.docx'}),\n",
       " Document(page_content='The secret of that charm many men and not a few women, from Miss Austen herself downwards, have felt, and like most charms it is a thing rather to be felt than to be explained. Elizabeth of course belongs to the allegro or allegra division of the army of Venus. Miss Austen was always provokingly chary of description in regard to her beauties; and except the fine eyes, and a hint or two that she had at any rate sometimes a bright complexion, and was not very tall, we hear nothing about her looks. But her chief difference from other heroines of the lively type seems to lie first in her being distinctly clever—almost strong-minded, in the better sense of that objectionable word—and secondly in her being entirely destitute of ill-nature for all her propensity to tease and the sharpness of her tongue. Elizabeth can give at least as good as she gets when she is attacked; but she never “scratches,” and she never attacks first. Some of the merest obsoletenesses of phrase and\\n{xxii}\\n manner give one or two of her early speeches a slight pertness, but that is nothing, and when she comes to serious business, as in the great proposal scene with Darcy (which is, as it should be, the climax of the interest of the book), and in the final ladies’ battle with Lady Catherine, she is unexceptionable. Then too she is a perfectly natural girl. She does not disguise from herself or anybody that she resents Darcy’s first ill-mannered personality with as personal a feeling. (By the way, the reproach that the ill-manners of this speech are overdone is certainly unjust; for things of the same kind, expressed no doubt less stiltedly but more coarsely, might have been heard in more than one ball-room during this very year from persons who ought to have been no worse bred than Darcy.) And she lets the injury done to Jane and the contempt shown to the rest of her family aggravate this resentment in the healthiest way in the world.', metadata={'source': './files/preface.docx'})]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore.similarity_search(\"Who is miss Austen\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
